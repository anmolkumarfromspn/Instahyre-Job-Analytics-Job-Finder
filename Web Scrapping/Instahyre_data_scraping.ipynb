{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958ff356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef5762a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the website to be scrapped\n",
    "website=\"https://www.instahyre.com/search-jobs/\"\n",
    "\n",
    "# get request to the url\n",
    "opts=Options()\n",
    "driver=webdriver.Chrome(opts)\n",
    "driver.get(website)\n",
    "\n",
    "# creating empty list for the data\n",
    "data=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7835c038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking total no of pages to be repeated for data collection\n",
    "pages= 500\n",
    "\n",
    "# running for loop for different pages upto n pages\n",
    "for i in range(pages):\n",
    "    print(\"Page\", i+1)\n",
    "\n",
    "    # making soup\n",
    "    html_code=driver.page_source\n",
    "    soup=BeautifulSoup(html_code,'html.parser')\n",
    "    \n",
    "    # all rows in one page\n",
    "    rows=soup.find_all(class_='row cursor-pointer')\n",
    "    \n",
    "    # run loop for each row to get the data by clicking on the view tab\n",
    "    for row in rows:\n",
    "        link=row.find('a')['href']\n",
    "\n",
    "        #printing each link of view tab\n",
    "        print(\"directing to link :\", link) \n",
    "        \n",
    "        # taking content_driver as a driver for content for each row \n",
    "        content_driver = webdriver.Chrome(opts)\n",
    "        content_driver.get(link)\n",
    "        \n",
    "        # making soup for content\n",
    "        content_html_code = content_driver.page_source\n",
    "        content_soup = BeautifulSoup(content_html_code, 'html.parser')\n",
    "        \n",
    "        # extracting required data from each content page\n",
    "        \n",
    "        # link itself contain the job_id https://www.instahyre.com/job-261410-admin-at-indihood-bangalore/\n",
    "        try:\n",
    "            job_id = int(link.split('-')[1])\n",
    "        except:\n",
    "            job_id = None\n",
    "        \n",
    "        # text of tag is itself the job_title\n",
    "        try:\n",
    "            job_title = content_soup.find(\"h1\").text.strip()\n",
    "        except:\n",
    "            job_title = None\n",
    "        \n",
    "        #text of tag is itself the company_name\n",
    "        try:\n",
    "            company_name = content_soup.find(class_=\"company-name\").text.strip()\n",
    "        except:\n",
    "            company_name = None\n",
    "        \n",
    "        #text of tag is itself the experience\n",
    "        try:\n",
    "            experience = content_soup.find(class_=\"experience\").text.strip()\n",
    "        except:\n",
    "            experience = None\n",
    "        \n",
    "        # text of tag is itself the job location\n",
    "        try:\n",
    "            job_locations = content_soup.find(class_=\"job-locations\").text.strip().replace(experience, \"\")\n",
    "        except:\n",
    "            job_locations = None\n",
    "        \n",
    "        # text of tag is itself the job hr_name\n",
    "        try:\n",
    "            HR_name = content_soup.find(class_=\"rec-name\").text.strip()\n",
    "        except:\n",
    "            HR_name = None\n",
    "        \n",
    "        # text of tag in respective attibute\n",
    "        try:\n",
    "            founded_in = content_soup.find(\"div\", {\"ng-if\": \"employer.company_founded\"}).text.strip()\n",
    "        except:\n",
    "            founded_in = None\n",
    "        \n",
    "        # text of tag in respective attibute\n",
    "        try:\n",
    "            employees_count = content_soup.find(\"div\", {\"ng-if\": \"employer.employee_count\"}).text.strip()\n",
    "        except:\n",
    "            employees_count = None\n",
    "        # there are multiple skills in their tag\n",
    "        try:\n",
    "            skill = content_soup.find(class_=\"tags job-description-skills\")\n",
    "        except:\n",
    "            skill = None\n",
    "\n",
    "        if skill and skill.children:\n",
    "            skill=skill.children\n",
    "        else:\n",
    "            skill=[skill]\n",
    "        \n",
    "        skills_list = []\n",
    "        \n",
    "        if skill is not None:\n",
    "            for j in skill:\n",
    "                try:\n",
    "                    j = j.text.strip()\n",
    "                except:\n",
    "                    pass\n",
    "                if (j and j != \"\\\\n\"):\n",
    "                    skills_list.append(j)\n",
    "                    \n",
    "        if skills_list is None:\n",
    "            skill=\"N/A\"\n",
    "        else:\n",
    "            skill= \", \".join(skills_list)\n",
    "            \n",
    "        # appending extracted data to data list   \n",
    "        data.append({\"company_name\" : company_name, \"job_title\" : job_title, \"job_locations\" : job_locations, \n",
    "                         \"experience\" : experience,\"hr_name\" : HR_name,\"founded_in\" : founded_in,\n",
    "                     \"employees_count\" : employees_count, \"skills\" : skill, \"job_id\" : job_id })\n",
    "        \n",
    "        # Return to the previous page\n",
    "        content_driver.back()\n",
    "        content_driver.quit()\n",
    "        \n",
    "    # again clicking the view tab for another row\n",
    "    next_page = driver.find_element(By.CSS_SELECTOR, '[ng-click=\"nextPage()\"]').click()\n",
    "    \n",
    "# printing no of data and data    \n",
    "print(len(data))\n",
    "print(\"data\",data)\n",
    "\n",
    "# converting list into datframe\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "           \n",
    "df.to_excel('G:\\My Drive\\Projects\\Instahyre Job Analytics\\Anmol_try_2.xlsx', columns=['company_name', 'job_title', 'job_locations', 'experience', 'hr_name', \n",
    "                                                    'founded_in', 'employees_count', 'skills','job_id'], index=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda0bd8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
